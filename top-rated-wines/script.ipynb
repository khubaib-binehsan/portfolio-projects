{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Wine Tasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file import\n",
    "\n",
    "dataset = pd.read_csv('./data/wine-tasting.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Manipulation**\n",
    "\n",
    "Extracting regions from titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting regions from title column\n",
    "\n",
    "# regex pattern that extracts the required substring\n",
    "pattern = re.compile(r'\\(.+\\)')\n",
    "\n",
    "def get_region(x):\n",
    "    \"\"\"\n",
    "    function that will passed to .apply function\n",
    "    the output will always be of the form (...foo...bar...)\n",
    "    \"\"\"\n",
    "\n",
    "    return ''.join(re.findall(pattern, x))\n",
    "\n",
    "def filter_region(string):\n",
    "    \"\"\"\n",
    "    after the substring is returned we need to clean it further\n",
    "    \"\"\"\n",
    "\n",
    "    # removing the first ( from the regex returned string\n",
    "    \n",
    "    truncated = string[1:]\n",
    "\n",
    "    # if there is only no ( in the truncated string that means our string is of the type\n",
    "    # foo...bar), therefore we return the string with last character also removed\n",
    "    \n",
    "    if truncated.count('(') == 0:\n",
    "        return truncated[:-1]\n",
    "    \n",
    "    # if there is only one ( in the truncated string that means our string is of the type\n",
    "    # foo...(bar)) or foo...(bar)...) or foo...(bar)...) therefore we return the string with last character also removed\n",
    "    \n",
    "    if truncated.count('(') == 1:\n",
    "        \n",
    "        # for the first case we just do as we did for the previous case\n",
    "        if truncated[-2:] == '))':\n",
    "            return truncated[:-1]\n",
    "        \n",
    "        # otherwise reverse the truncated string, find the first ( character then do arithmetic so\n",
    "        # it can be used as a starting index for the previous string and then return the string\n",
    "        # with first and last character removed\n",
    "\n",
    "        else:\n",
    "            return truncated[-truncated[::-1].find('(')-1:][1:-1]\n",
    "        \n",
    "    if truncated.count('(') == 2:\n",
    "        \n",
    "\n",
    "        if truncated[-2:] == '))':\n",
    "            return truncated[truncated.find('('):][1:-1]\n",
    "        \n",
    "        else:\n",
    "            return truncated[-truncated[::-1].find('(')-1:][1:-1]\n",
    "        \n",
    "    if truncated.count('(') > 2:\n",
    "        return truncated[:-1]\n",
    "\n",
    "# extracts substring\n",
    "dataset['region'] = dataset['title'].apply(get_region)\n",
    "\n",
    "# filters the region substring\n",
    "dataset['region'] = dataset['region'].apply(filter_region)\n",
    "\n",
    "# returns NaN value if string is empty\n",
    "dataset['region'] = dataset['region'].apply(lambda x: np.nan if len(x)== 0 else x)\n",
    "\n",
    "# dataset['region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dropping columns and rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "\n",
    "dataset.drop(\n",
    "    ['designation', 'region_1', 'region_2', 'taster_twitter_handle'],\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (129971, 11)\n",
      "After:  (89022, 11)\n"
     ]
    }
   ],
   "source": [
    "# dropping rows which contain null values\n",
    "\n",
    "print(f\"Before: {dataset.shape}\")\n",
    "\n",
    "dataset.dropna(\n",
    "    subset=['country', 'points', 'price', 'province','taster_name', 'title', 'variety', 'winery', 'region'],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "print(f\"After:  {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints function\n",
    "\n",
    "def constrainted(df: pd.DataFrame, column: str, _query: str = None) -> list[bool]:\n",
    "    \n",
    "    return df[column].isin(\n",
    "        df[[column]]\n",
    "        .assign(count=0)\n",
    "        .groupby([column])\n",
    "        .count()\n",
    "        .query('count ' + _query)\n",
    "        .index\n",
    "        )\n",
    "\n",
    "def constraint_check(df: pd.DataFrame, column: str, lower_bound: int) -> tuple[bool, int]:\n",
    "    value = (\n",
    "        df[[column]]\n",
    "        .assign(count=0)\n",
    "        .groupby([column])\n",
    "        .count()\n",
    "        ['count']\n",
    "        .min()\n",
    "    )\n",
    "\n",
    "    out = (value >= lower_bound, value)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining constraints\n",
    "\n",
    "constraints = {\n",
    "    'winery' : '>= 6',\n",
    "    'variety' : '>= 3',\n",
    "    'region' : '>= 6',\n",
    "    'taster_name' : '>= 100'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winery : 1\n",
      "variety : 1\n",
      "region : 3\n",
      "province : 6\n",
      "taster_name : 112\n",
      "country : 6\n",
      "(68969, 11)\n"
     ]
    }
   ],
   "source": [
    "# iterating through each of the constraint\n",
    "\n",
    "for column, _query in constraints.items():\n",
    "    dataset = dataset[constrainted(dataset, column, _query)]\n",
    "\n",
    "# checking constraints\n",
    "\n",
    "for item in ['winery', 'variety', 'region', 'province', 'taster_name', 'country']:\n",
    "    print(item, ':', constraint_check(dataset, item, 10)[1])\n",
    "\n",
    "# rechecking how many rows we are left with\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the final dataset\n",
    "\n",
    "wine_tasting_clean = (\n",
    "    dataset\n",
    "    .drop(['description'], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extracting common words**\n",
    "\n",
    "Extracting common words that the reviewers are using in their reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(x):\n",
    "    \n",
    "    out = x.lower()\n",
    "    out = out.replace(\"'s\", '')\n",
    "    out = out.replace(\",\", '')\n",
    "    out = out.replace(\".\", '')\n",
    "    out = out.replace(\"!\", '')\n",
    "    out = out.replace(\";\", '')\n",
    "    out = out.replace(\":\", '')\n",
    "    out = out.replace('\"', '')\n",
    "    out = out.split(' ')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from each of the row in dataset[].apply() to convert a list of strings\n",
    "# to list of list of string:\n",
    "\n",
    "# [a,b,c] -> [[a], [b], [c]\n",
    "\n",
    "# and them creates a dataframe from it\n",
    "temp = pd.DataFrame([\n",
    "    item for item in dataset['description'].apply(get_words)\n",
    "])\n",
    "\n",
    "# first converts the dataframe to numpy array and then uses .ravel() to create a stack from it\n",
    "# then creates pandas series from it\n",
    "temp = pd.Series(temp.to_numpy().ravel())\n",
    "\n",
    "# rows have None value, replaces them with np.nan so that it can be dropped using dropna()\n",
    "temp = temp.fillna(value=np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afterwards, using the series, it creates a dataframe\n",
    "# creates a count column with 0s\n",
    "# groups using the column values and counts the number of rows each group contains\n",
    "# reset index, sort_values in descending order and then stores the value in .csv file\n",
    "\n",
    "words = (\n",
    "    pd.DataFrame(temp, columns=['column'])\n",
    "    .assign(count=0)\n",
    "    .groupby('column')\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .sort_values('count', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exporting files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./clean-data')\n",
    "except: pass\n",
    "\n",
    "wine_tasting_clean.to_csv('./clean-data/wine_tasting_clean.csv', index=False)\n",
    "\n",
    "words.to_csv('./clean-data/words.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-viz-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
